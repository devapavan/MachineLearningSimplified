{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook Content \n",
    "\n",
    "### Evaluation Metrics for Regression\n",
    "1. Explained-Variance-Score\n",
    "2. Max-error\n",
    "3. Mean-Absolute-Error\n",
    "4. Mean-Squared-Error\n",
    "5. Mean-Squared-Logarithmic-Error\n",
    "6. Median-Absolute-Error\n",
    "7. R²-score\n",
    "8. Mean-Percentage-Erro\n",
    "9. Mean-Absolute-Percentage-Error\n",
    "10. Weighted-Mean-Absolute-erro\n",
    "11. Tips-for-Metric-Selection\n",
    "12. Cross-Validation\n",
    "13. StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics for Regression\n",
    "The **sklearn.metrics module implements several loss, score, and utility functions to measure regression performance**. Some of those have been enhanced to handle the **multioutput case**: mean_squared_error, mean_absolute_error, explained_variance_score and r2_score.These functions have an **multioutput keyword argument which specifies the way the scores or losses for each individual target should be averaged**. The default is 'uniform_average', which specifies a uniformly weighted mean over outputs.<br> \n",
    "If an ndarray of shape (n_outputs,) is passed, then its entries are interpreted as weights and an according weighted average is returned. If multioutput is 'raw_values' is specified, then all unaltered individual scores or losses will be returned in an array of shape (n_outputs,).\n",
    "<br><br>The **r2_score and explained_variance_score accept an additional value 'variance_weighted'** for the multioutput parameter. This option leads to a weighting of each individual score by the variance of the corresponding target variable. This setting quantifies the globally captured unscaled variance. If the target variables are of different scale, then this score puts more importance on well explaining the higher variance variables. multioutput='variance_weighted' is the default value for r2_score for backward compatibility. This will be changed to uniform_average in the future.<br><br>\n",
    "\n",
    "<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Code\" role=\"tab\" aria-controls=\"messages\">Go to Code<span class=\"badge badge-primary badge-pill\"> </span></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explained Variance Score\n",
    "The explained_variance_score **computes the explained variance regression score**. **Explained variation measures the proportion to which a mathematical model accounts for the variation (dispersion)** of a given data set. Often, variation is quantified as variance; then, the more specific term explained variance can be used.<br><br>The best possible score is 1.0, lower values are worse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $\\hat{y}$ is the estimated target output, $y$ the corresponding (correct) target output, and $Var$ is Variance, the square of the standard deviation, then the explained variance is estimated as follow:\n",
    "\n",
    "$explained\\_{}variance(y, \\hat{y}) = 1 - \\frac{Var\\{ y - \\hat{y}\\}}{Var\\{y\\}}$<br><br>\n",
    "<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Code\" role=\"tab\" aria-controls=\"messages\">Go to Code<span class=\"badge badge-primary badge-pill\"> </span></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max error\n",
    "The max_error function computes the **maximum residual error** , a metric that captures the worst case error between the predicted value and the true value. In a perfectly fitted single output regression model, max_error would be 0 on the training set and though this would be highly unlikely in the real world, this metric shows the extent of error that the model had when it was fitted.\n",
    "\n",
    "If $\\hat{y}_i$ is the predicted value of the $i$-th sample, and $y_i$ is the corresponding true value, then the max error is defined as:\n",
    "\n",
    "$\\text{Max Error}(y, \\hat{y}) = max(| y_i - \\hat{y}_i |)$<br><br>\n",
    "<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Code\" role=\"tab\" aria-controls=\"messages\">Go to Code<span class=\"badge badge-primary badge-pill\"> </span></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Absolute Error\n",
    "The mean_absolute_error function computes mean absolute error, a risk metric corresponding to the expected value of the absolute error loss or $l1$-norm loss.In statistics, mean absolute error (MAE) is a **measure of errors between paired observations** expressing the same phenomenon.\n",
    "\n",
    "If $\\hat{y}_i$ is the predicted value of the $i$-th sample, and $y_i$ is the corresponding true value, then the mean absolute error (MAE) estimated over $n_{\\text{samples}}$ is defined as:\n",
    "\n",
    "$\\text{MAE}(y, \\hat{y}) = \\frac{1}{n_{\\text{samples}}} \\sum_{i=0}^{n_{\\text{samples}}-1} \\left| y_i - \\hat{y}_i \\right|$.<br><br>\n",
    "<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Code\" role=\"tab\" aria-controls=\"messages\">Go to Code<span class=\"badge badge-primary badge-pill\"> </span></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Squared Error\n",
    "The mean_squared_error function computes mean square error, a risk metric **corresponding to the expected value of the squared (quadratic) error or loss**.\n",
    "\n",
    "If $\\hat{y}_i$ is the predicted value of the $i$-th sample, and $y_i$ is the corresponding true value, then the mean squared error (MSE) estimated over $n_{\\text{samples}}$ is defined as\n",
    "\n",
    "$\\text{MSE}(y, \\hat{y}) = \\frac{1}{n_\\text{samples}} \\sum_{i=0}^{n_\\text{samples} - 1} (y_i - \\hat{y}_i)^2.$<br><br>\n",
    "<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Code\" role=\"tab\" aria-controls=\"messages\">Go to Code<span class=\"badge badge-primary badge-pill\"> </span></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Squared Logarithmic Error\n",
    "The mean_squared_log_error function computes a **risk metric corresponding to the expected value of the squared logarithmic (quadratic) error or loss.**\n",
    "\n",
    "If $\\hat{y}_i$ is the predicted value of the $i$-th sample, and $y_i$ is the corresponding true value, then the mean squared logarithmic error (MSLE) estimated over $n_{\\text{samples}}$ is defined as:\n",
    "\n",
    "$\\text{MSLE}(y, \\hat{y}) = \\frac{1}{n_\\text{samples}} \\sum_{i=0}^{n_\\text{samples} - 1} (\\log_e (1 + y_i) - \\log_e (1 + \\hat{y}_i) )^2.$\n",
    "Where $\\log_e (x)$ means the natural logarithm of $x$. <br>\n",
    "**This metric is best to use when targets having exponential growth, such as population counts**, average sales of a commodity over a span of years etc. Note that this metric penalizes an under-predicted estimate greater than an over-predicted estimate.\n",
    "<br><br><a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Code\" role=\"tab\" aria-controls=\"messages\">Go to Code<span class=\"badge badge-primary badge-pill\"> </span></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Median Absolute Error\n",
    "The median_absolute_error is particularly interesting because **it is robust to outliers**. The loss is calculated by taking the **median of all absolute differences between the target and the prediction**.<br><br>\n",
    "If $\\hat{y}_i$ is the predicted value of the $i$-th sample and $y_i$ is the corresponding true value, then the median absolute error (MedAE) estimated over $n_{\\text{samples}}$ is defined as\n",
    "\n",
    "$\\text{MedAE}(y, \\hat{y}) = \\text{median}(\\mid y_1 - \\hat{y}_1 \\mid, \\ldots, \\mid y_n - \\hat{y}_n \\mid).$\n",
    "\n",
    "<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Code\" role=\"tab\" aria-controls=\"messages\">Go to Code<span class=\"badge badge-primary badge-pill\"> </span></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R² score\n",
    "The r2_score function **computes the coefficient of determination**, usually denoted as R².<br><br>\n",
    "It represents the **proportion of variance (of y) that has been explained by the independent variables** in the model. It provides an **indication of goodness of fit** and therefore a measure of how well unseen samples are likely to be predicted by the model, through the proportion of explained variance.<br><br>\n",
    "As such variance is dataset dependent, **R² may not be meaningfully comparable across different datasets**. <br>Best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a R² score of 0.0.\n",
    "\n",
    "If $\\hat{y}_i$ is the predicted value of the $i$-th sample and $y_i$ is the corresponding true value for total $n$ samples, the estimated R² is defined as:\n",
    "\n",
    "$R^2(y, \\hat{y}) = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}$ <br>\n",
    "where $\\bar{y} = \\frac{1}{n} \\sum_{i=1}^{n} y_i$ and $\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 = \\sum_{i=1}^{n} \\epsilon_i^2$ <br>\n",
    "\n",
    "\n",
    "<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Code\" role=\"tab\" aria-controls=\"messages\">Go to Code<span class=\"badge badge-primary badge-pill\"> </span></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Model-Evaluation\" role=\"tab\" aria-controls=\"messages\">Go to top<span class=\"badge badge-primary badge-pill\"></span></a>\n"
   ]
  },
  {
   "attachments": {
    "MPE.svg": {
     "image/svg+xml": [
      "<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="26.481ex" height="6.843ex" style="vertical-align: -3.005ex;" viewBox="0 -1652.5 11401.6 2946.1" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">{\displaystyle {\text{MPE}}={\frac {100\%}{n}}\sum _{t=1}^{n}{\frac {a_{t}-f_{t}}{a_{t}}}}</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMAIN-4D" d="M132 622Q125 629 121 631T105 634T62 637H29V683H135Q221 683 232 682T249 675Q250 674 354 398L458 124L562 398Q666 674 668 675Q671 681 683 682T781 683H887V637H854Q814 636 803 634T785 622V61Q791 51 802 49T854 46H887V0H876Q855 3 736 3Q605 3 596 0H585V46H618Q660 47 669 49T688 61V347Q688 424 688 461T688 546T688 613L687 632Q454 14 450 7Q446 1 430 1T410 7Q409 9 292 316L176 624V606Q175 588 175 543T175 463T175 356L176 86Q187 50 261 46H278V0H269Q254 3 154 3Q52 3 37 0H29V46H46Q78 48 98 56T122 69T132 86V622Z"></path>
<path stroke-width="1" id="E1-MJMAIN-50" d="M130 622Q123 629 119 631T103 634T60 637H27V683H214Q237 683 276 683T331 684Q419 684 471 671T567 616Q624 563 624 489Q624 421 573 372T451 307Q429 302 328 301H234V181Q234 62 237 58Q245 47 304 46H337V0H326Q305 3 182 3Q47 3 38 0H27V46H60Q102 47 111 49T130 61V622ZM507 488Q507 514 506 528T500 564T483 597T450 620T397 635Q385 637 307 637H286Q237 637 234 628Q231 624 231 483V342H302H339Q390 342 423 349T481 382Q507 411 507 488Z"></path>
<path stroke-width="1" id="E1-MJMAIN-45" d="M128 619Q121 626 117 628T101 631T58 634H25V680H597V676Q599 670 611 560T625 444V440H585V444Q584 447 582 465Q578 500 570 526T553 571T528 601T498 619T457 629T411 633T353 634Q266 634 251 633T233 622Q233 622 233 621Q232 619 232 497V376H286Q359 378 377 385Q413 401 416 469Q416 471 416 473V493H456V213H416V233Q415 268 408 288T383 317T349 328T297 330Q290 330 286 330H232V196V114Q232 57 237 52Q243 47 289 47H340H391Q428 47 452 50T505 62T552 92T584 146Q594 172 599 200T607 247T612 270V273H652V270Q651 267 632 137T610 3V0H25V46H58Q100 47 109 49T128 61V619Z"></path>
<path stroke-width="1" id="E1-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path>
<path stroke-width="1" id="E1-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path>
<path stroke-width="1" id="E1-MJMAIN-30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path>
<path stroke-width="1" id="E1-MJMAIN-25" d="M465 605Q428 605 394 614T340 632T319 641Q332 608 332 548Q332 458 293 403T202 347Q145 347 101 402T56 548Q56 637 101 693T202 750Q241 750 272 719Q359 642 464 642Q580 642 650 732Q662 748 668 749Q670 750 673 750Q682 750 688 743T693 726Q178 -47 170 -52Q166 -56 160 -56Q147 -56 142 -45Q137 -36 142 -27Q143 -24 363 304Q469 462 525 546T581 630Q528 605 465 605ZM207 385Q235 385 263 427T292 548Q292 617 267 664T200 712Q193 712 186 709T167 698T147 668T134 615Q132 595 132 548V527Q132 436 165 403Q183 385 203 385H207ZM500 146Q500 234 544 290T647 347Q699 347 737 292T776 146T737 0T646 -56Q590 -56 545 0T500 146ZM651 -18Q679 -18 707 24T736 146Q736 215 711 262T644 309Q637 309 630 306T611 295T591 265T578 212Q577 200 577 146V124Q577 -18 647 -18H651Z"></path>
<path stroke-width="1" id="E1-MJMATHI-6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJSZ2-2211" d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path>
<path stroke-width="1" id="E1-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path>
<path stroke-width="1" id="E1-MJMATHI-61" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path>
<path stroke-width="1" id="E1-MJMATHI-66" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMAIN-4D"></use>
 <use xlink:href="#E1-MJMAIN-50" x="917" y="0"></use>
 <use xlink:href="#E1-MJMAIN-45" x="1599" y="0"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="2558" y="0"></use>
<g transform="translate(3614,0)">
<g transform="translate(120,0)">
<rect stroke="none" width="2455" height="60" x="0" y="220"></rect>
<g transform="translate(60,676)">
 <use xlink:href="#E1-MJMAIN-31"></use>
 <use xlink:href="#E1-MJMAIN-30" x="500" y="0"></use>
 <use xlink:href="#E1-MJMAIN-30" x="1001" y="0"></use>
 <use xlink:href="#E1-MJMAIN-25" x="1501" y="0"></use>
</g>
 <use xlink:href="#E1-MJMATHI-6E" x="927" y="-686"></use>
</g>
</g>
<g transform="translate(6476,0)">
 <use xlink:href="#E1-MJSZ2-2211" x="0" y="0"></use>
<g transform="translate(142,-1090)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-3D" x="361" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="1140" y="0"></use>
</g>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-6E" x="721" y="1627"></use>
</g>
<g transform="translate(8087,0)">
<g transform="translate(120,0)">
<rect stroke="none" width="3074" height="60" x="0" y="220"></rect>
<g transform="translate(60,725)">
 <use xlink:href="#E1-MJMATHI-61" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="748" y="-213"></use>
 <use xlink:href="#E1-MJMAIN-2212" x="1107" y="0"></use>
<g transform="translate(2108,0)">
 <use xlink:href="#E1-MJMATHI-66" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="693" y="-213"></use>
</g>
</g>
<g transform="translate(1094,-686)">
 <use xlink:href="#E1-MJMATHI-61" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="748" y="-213"></use>
</g>
</g>
</g>
</g>
</svg>"
     ]
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Percentage Error\n",
    "In statistics, the mean percentage error (MPE) is the computed average of percentage errors by which forecasts of a model differ from actual values of the quantity being forecast.\n",
    "\n",
    "The formula for the mean percentage error is:\n",
    "![MPE.svg](attachment:MPE.svg) <br>\n",
    "where $a_t$ is the actual value of the quantity being forecast, $f_t$ is the forecast, and n is the number of different times for which the variable is forecast.\n",
    "\n",
    "Because actual rather than absolute values of the forecast errors are used in the formula, positive and negative forecast errors can offset each other; as a result the formula can be used as a measure of the bias in the forecasts.\n",
    "\n",
    "A disadvantage of this measure is that it is undefined whenever a single actual value is zero.<br>\n",
    "The fuction defination of MPE is given below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MPE(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean((y_true - y_pred) / y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Model-Evaluation\" role=\"tab\" aria-controls=\"messages\">Go to top<span class=\"badge badge-primary badge-pill\"></span></a>\n"
   ]
  },
  {
   "attachments": {
    "Mape.svg": {
     "image/svg+xml": [
      "<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="22.483ex" height="6.843ex" style="vertical-align: -3.005ex;" viewBox="0 -1652.5 9680.2 2946.1" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">{\displaystyle {\mbox{M}}={\frac {1}{n}}\sum _{t=1}^{n}\left|{\frac {A_{t}-F_{t}}{A_{t}}}\right|,}</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMAIN-4D" d="M132 622Q125 629 121 631T105 634T62 637H29V683H135Q221 683 232 682T249 675Q250 674 354 398L458 124L562 398Q666 674 668 675Q671 681 683 682T781 683H887V637H854Q814 636 803 634T785 622V61Q791 51 802 49T854 46H887V0H876Q855 3 736 3Q605 3 596 0H585V46H618Q660 47 669 49T688 61V347Q688 424 688 461T688 546T688 613L687 632Q454 14 450 7Q446 1 430 1T410 7Q409 9 292 316L176 624V606Q175 588 175 543T175 463T175 356L176 86Q187 50 261 46H278V0H269Q254 3 154 3Q52 3 37 0H29V46H46Q78 48 98 56T122 69T132 86V622Z"></path>
<path stroke-width="1" id="E1-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path>
<path stroke-width="1" id="E1-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path>
<path stroke-width="1" id="E1-MJMATHI-6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJSZ2-2211" d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path>
<path stroke-width="1" id="E1-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path>
<path stroke-width="1" id="E1-MJMAIN-7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path>
<path stroke-width="1" id="E1-MJMATHI-41" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path>
<path stroke-width="1" id="E1-MJMATHI-46" d="M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2223" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMAIN-4D" x="0" y="0"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="1195" y="0"></use>
<g transform="translate(2251,0)">
<g transform="translate(120,0)">
<rect stroke="none" width="720" height="60" x="0" y="220"></rect>
 <use xlink:href="#E1-MJMAIN-31" x="110" y="676"></use>
 <use xlink:href="#E1-MJMATHI-6E" x="60" y="-686"></use>
</g>
</g>
<g transform="translate(3378,0)">
 <use xlink:href="#E1-MJSZ2-2211" x="0" y="0"></use>
<g transform="translate(142,-1090)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-3D" x="361" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="1140" y="0"></use>
</g>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-6E" x="721" y="1627"></use>
</g>
<g transform="translate(4989,0)">
<g transform="translate(0,1394)">
 <use xlink:href="#E1-MJMAIN-2223" x="0" y="-751"></use>
<g transform="translate(0,-1241.921016607499) scale(1,0.38737818456391343)">
 <use xlink:href="#E1-MJMAIN-2223"></use>
</g>
 <use xlink:href="#E1-MJMAIN-2223" x="0" y="-2040"></use>
</g>
<g transform="translate(278,0)">
<g transform="translate(120,0)">
<rect stroke="none" width="3448" height="60" x="0" y="220"></rect>
<g transform="translate(60,677)">
 <use xlink:href="#E1-MJMATHI-41" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="1061" y="-213"></use>
 <use xlink:href="#E1-MJMAIN-2212" x="1328" y="0"></use>
<g transform="translate(2329,0)">
 <use xlink:href="#E1-MJMATHI-46" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="910" y="-213"></use>
</g>
</g>
<g transform="translate(1171,-737)">
 <use xlink:href="#E1-MJMATHI-41" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="1061" y="-213"></use>
</g>
</g>
</g>
<g transform="translate(3966,1394)">
 <use xlink:href="#E1-MJMAIN-2223" x="0" y="-751"></use>
<g transform="translate(0,-1241.921016607499) scale(1,0.38737818456391343)">
 <use xlink:href="#E1-MJMAIN-2223"></use>
</g>
 <use xlink:href="#E1-MJMAIN-2223" x="0" y="-2040"></use>
</g>
</g>
 <use xlink:href="#E1-MJMAIN-2C" x="9401" y="0"></use>
</g>
</svg>"
     ]
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Absolute Percentage Error\n",
    "It is a simple average of absolute percentage errors. The MAPE calculation is as follows:\n",
    "![Mape.svg](attachment:Mape.svg)\n",
    "where $A_t$ is the actual value and $F_t$ is the forecast value. The MAPE is also sometimes reported as a percentage, which is the above equation multiplied by 100. The difference between $A_t$ and $F_t$ is divided by the actual value At again. <br>\n",
    "It **cannot be used if there are zero values** (which sometimes happens for example in demand data) because there would be a division by zero.<br>\n",
    "For forecasts which are too low the percentage error cannot exceed 100%, but **for forecasts which are too high there is no upper limit to the percentage error**.<br>\n",
    "\n",
    "The fuction defination of MAPE is Given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAPE(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return (np.mean(np.abs((y_true - y_pred) / y_true)) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Model-Evaluation\" role=\"tab\" aria-controls=\"messages\">Go to top<span class=\"badge badge-primary badge-pill\"></span></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted Mean Absolute error\n",
    "The wMAPE is the metric in which the sales are weighted by sales volumne. Weighted Mean Absolute Percentage Error, as the name suggests, is a **measure that gives greater importance to faster selling products**. Thus it overcomes one of the potential drawbacks of MAPE. There is a very simple way to calculate WMAPE. This involves adding together the absolute errors at the detailed level, then calculating the total of the errors as a percentage of total sales.  This method of calculation leads to the additional benefit that it is robust to individual instances when the base is zero, thus overcoming the divide by zero problem that often occurs with MAPE.\n",
    "\n",
    "WMAPE is a highly useful measure and is becoming increasingly popular both in corporate KPIs and for operational use. It is easily calculated and gives a concise forecast accuracy measurement that can be used to summarise performance at any detailed level across any grouping of products and/or time periods. If a measure of accuracy required this is calculated as 100 - WMAPE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, in order to show how to run the different Accuracy metrics, we will be prforming Random Forest Regression on a dataset the download link for which is given below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009<br>\n",
    "We will start by importing the necessary libraries and the required dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Model-Evaluation\" role=\"tab\" aria-controls=\"messages\">Go to top<span class=\"badge badge-primary badge-pill\"></span></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Importing the libraries \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset/winequality-red.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next step is to divide the data into “attributes” and “labels”. X variable contains all the attributes/features and y variable contains labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates','alcohol']]\n",
    "y = data['quality']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we split 80% of the data to the training set while 20% of the data to test set using below code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will run random forest regression on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=1000, n_jobs=None, oob_score=False,\n",
       "                      random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import RF Regressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's do prediction on test data.\n",
    "\n",
    "y_pred = rf.predict(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Code_\n",
    "Now we can calculate the accuracy of our model using the different accuracy metrics that we have explained above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________________\n",
      "Explained variance Score: [0.45337001]\n",
      "_____________________________________\n",
      "Max Error: 2.615\n",
      "_____________________________________\n",
      "Mean Absolute Error: 0.40428437500000003\n",
      "_____________________________________\n",
      "Mean Squared Error: 0.318432278125\n",
      "_____________________________________\n",
      "Root Mean Squared Error: 0.5642980401569724\n",
      "_____________________________________\n",
      "Mean Squared Log Error: 0.008019925336798525\n",
      "_____________________________________\n",
      "Median Absolute Error: 0.3089999999999997\n",
      "_____________________________________\n",
      "Mean Percentage Error: -0.024683098958333333\n",
      "_____________________________________\n",
      "Mean Absolute Percentage Error: 7.658587425595238\n"
     ]
    }
   ],
   "source": [
    "#Error Calculations\n",
    "from sklearn import metrics\n",
    "#Explained Variance Score\n",
    "print(\"_____________________________________\")\n",
    "print('Explained variance Score:', metrics.explained_variance_score(y_test, y_pred, multioutput='raw_values'))\n",
    "explained_variance_score= metrics.explained_variance_score(y_test, y_pred, multioutput='raw_values')\n",
    "#Max Error\n",
    "print(\"_____________________________________\")\n",
    "print('Max Error:', metrics.max_error(y_test, y_pred))\n",
    "max_error=metrics.max_error(y_test, y_pred)\n",
    "#Mean Absolute Error\n",
    "print(\"_____________________________________\")\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "mean_absolute_error=metrics.mean_absolute_error(y_test, y_pred)\n",
    "#Mean Squared Error\n",
    "print(\"_____________________________________\")\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred)) \n",
    "mean_squared_error=metrics.mean_squared_error(y_test, y_pred)\n",
    "#Root Mean Squared Error\n",
    "print(\"_____________________________________\")\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "root_mean_squared_error=np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "#Mean Squared Log Error\n",
    "print(\"_____________________________________\")\n",
    "print('Mean Squared Log Error:', metrics.mean_squared_log_error(y_test, y_pred))\n",
    "mean_squared_log_error=metrics.mean_squared_log_error(y_test, y_pred)\n",
    "#Median Absolute Error\n",
    "print(\"_____________________________________\")\n",
    "print('Median Absolute Error:', metrics.median_absolute_error(y_test, y_pred))\n",
    "median_absolute_error=metrics.median_absolute_error(y_test, y_pred)\n",
    "#Median Absolute Error\n",
    "print(\"_____________________________________\")\n",
    "print('Mean Percentage Error:', MPE(y_test, y_pred))\n",
    "mean_percentage_error=MPE(y_test, y_pred)\n",
    "#Median Absolute Error\n",
    "print(\"_____________________________________\")\n",
    "print('Mean Absolute Percentage Error:', MAPE(y_test, y_pred))\n",
    "mean_absolute_percentage_error=MAPE(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe of errors given by all the metrics explained above\n",
    "data={\"Error Metric\":['Explained variance Score', 'Max Error', 'Mean Absolute Error', 'Mean Squared Error', 'Root Mean Squared Error','Mean Squared Log Error','Median Absolute Error','Mean Percentage Error','Mean Absolute Percentage Error'],\n",
    "      \"Score\":[\"%.4f\" % explained_variance_score, \"%.4f\" % max_error, \"%.4f\" % mean_absolute_error, \"%.4f\" % mean_squared_error, \"%.4f\" % root_mean_squared_error, \"%.4f\" % mean_squared_log_error, \"%.4f\" % median_absolute_error, \"%.4f\" % mean_percentage_error, \"%.4f\" % mean_absolute_percentage_error]}\n",
    "error_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error Metric</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explained variance Score</td>\n",
       "      <td>0.4534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Max Error</td>\n",
       "      <td>2.6150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mean Absolute Error</td>\n",
       "      <td>0.4043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mean Squared Error</td>\n",
       "      <td>0.3184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Root Mean Squared Error</td>\n",
       "      <td>0.5643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mean Squared Log Error</td>\n",
       "      <td>0.0080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Median Absolute Error</td>\n",
       "      <td>0.3090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mean Percentage Error</td>\n",
       "      <td>-0.0247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mean Absolute Percentage Error</td>\n",
       "      <td>7.6586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Error Metric    Score\n",
       "0        Explained variance Score   0.4534\n",
       "1                       Max Error   2.6150\n",
       "2             Mean Absolute Error   0.4043\n",
       "3              Mean Squared Error   0.3184\n",
       "4         Root Mean Squared Error   0.5643\n",
       "5          Mean Squared Log Error   0.0080\n",
       "6           Median Absolute Error   0.3090\n",
       "7           Mean Percentage Error  -0.0247\n",
       "8  Mean Absolute Percentage Error   7.6586"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Model-Evaluation\" role=\"tab\" aria-controls=\"messages\">Go to top<span class=\"badge badge-primary badge-pill\"></span></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tips for Metric Selection\n",
    "- The **MAE is also the most intuitive of the metrics** one should by just looking at the absolute difference between the data and the model’s predictions<br>\n",
    "\n",
    "\n",
    "- MAE does not indicate underperformance or overperformance of the model (whether or not the model under or overshoots actual data). Each residual contributes proportionally to the total amount of error, meaning that larger errors will contribute linearly to the overall error<br> \n",
    "\n",
    "\n",
    "- A **small MAE** suggests the model is great at prediction, while a **large MAE** suggests that, model may have trouble in certain areas. A MAE of 0 means that your model is a perfect predictor of the outputs (but this will almost never happen)<br><br>\n",
    "\n",
    "\n",
    "- While the MAE is easily interpretable, using the absolute value of the residual often is not as desirable as squaring this difference. Depending on how the model to treat outliers, or extreme values, in the data, one may want to bring more attention to these outliers or downplay them. The issue of outliers can play a major role in which error metric you use<br>\n",
    "\n",
    "\n",
    "- Because of squaring the difference, the **MSE will almost always be bigger than the MAE**. For this reason, we cannot directly compare the MAE to the MSE. **one can only compare model’s error metrics to those of a competing model**<br>\n",
    "\n",
    "- The effect of the square term in the MSE equation is most apparent with the presence of outliers in our data. **While each residual in MAE contributes proportionally to the total error, the error grows quadratically in MSE**<br><br>\n",
    "\n",
    "\n",
    "- RMSE is the square root of the MSE. Because the **MSE is squared, its units do not match that of the original output**. Researchers will often use **RMSE to convert the error metric** back into similar units, making interpretation easier<br>\n",
    "\n",
    "\n",
    "- Taking the square root before they are averaged, **RMSE gives a relatively high weight to large errors**, so RMSE should be useful when large errors are undesirable.<br><br>\n",
    "\n",
    "\n",
    "- Just as MAE is the average magnitude of error produced by your model, the **MAPE is how far the model’s predictions are off** from their corresponding outputs on average. Like MAE, MAPE also has a clear interpretation since percentages are easier for people to conceptualize. **Both MAPE and MAE are robust to the effects of outliers**<br>\n",
    "\n",
    "\n",
    "- Many of MAPE’s weaknesses actually stem from use division operation. MAPE is **undefined for data points where the value is 0**. Similarly, the MAPE can grow unexpectedly large if the actual values are exceptionally small themselves<br>\n",
    "\n",
    "\n",
    "- Finally, the MAPE is **biased towards predictions** that are systematically less than the actual values themselves. That is to say, MAPE will be lower when the prediction is lower than the actual compared to a prediction that is higher by the same amount. \n",
    "\n",
    "The table given below can also be helpful in regard to metric understanding:\n",
    "\n",
    "\n",
    "|Acroynm|Full Name|Residual Operation?|Robust To Outliers|\n",
    "|-------|---------|-------------------|------------------|\n",
    "|MAE|Mean Absolute Error|Absolute Value|Yes|\n",
    "|MSE|Mean Squared Error\tSquare|No|No|\n",
    "|RMSE|Root Mean Squared Error|Square|No|\n",
    "|MAPE|Mean Absolute Percentage Error|Absolute Value|Yes|\n",
    "|MPE|Mean Percentage Error|N/A|Yes|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Model-Evaluation\" role=\"tab\" aria-controls=\"messages\">Go to top<span class=\"badge badge-primary badge-pill\"></span></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation\n",
    "Cross-validation is a resampling procedure used to evaluate machine learning models on a limited data sample.\n",
    "Cross-validation is primarily used in applied machine learning to estimate the skill of a machine learning model on unseen data. That is, to use a limited sample in order to estimate how the model is expected to perform in general when used to make predictions on data not used during the training of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K-Folds Cross Validation**\n",
    "<br>In K-Folds Cross Validation we split our data into k different subsets (or folds). We use k-1 subsets to train our data and leave the last subset (or the last fold) as test data. We then average the model against each of the folds and then finalize our model. After that we test it against the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 2)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    # Split train-test\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.39817868338557993\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators = 100, random_state = 42)\n",
    "#Train the model on training data\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_kfold = rf.predict(X_test)\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred_kfold)) \n",
    "mean_squared_error=metrics.mean_squared_error(y_test, y_pred_kfold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Model-Evaluation\" role=\"tab\" aria-controls=\"messages\">Go to top<span class=\"badge badge-primary badge-pill\"></span></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StratifiedKFold\n",
    "StratifiedKFold is a variation of KFold. First, StratifiedKFold shuffles your data, after that splits the data into n_splits parts and Done. Now, it will use each part as a test set. Note that it only and always shuffles data one time before splitting.\n",
    "\n",
    "\n",
    "**Difference in KFold and ShuffleSplit output**\n",
    "\n",
    "KFold will divide your data set into prespecified number of folds, and every sample must be in one and only one fold. A fold is a subset of your dataset.\n",
    "\n",
    "ShuffleSplit will randomly sample your entire dataset during each iteration to generate a training set and a test set. The test_size and train_size parameters control how large the test and training test set should be for each iteration. Since you are sampling from the entire dataset during each iteration, values selected during one iteration, could be selected again during another iteration.\n",
    "\n",
    "Summary: ShuffleSplit works iteratively, KFold just divides the dataset into k folds.\n",
    "\n",
    "**Difference when doing validation**\n",
    "\n",
    "In KFold, during each round you will use one fold as the test set and all the remaining folds as your training set. However, in ShuffleSplit, during each round n you should only use the training and test set from iteration n. As your data set grows, cross validation time increases, making shufflesplits a more attractive alternate. If you can train your algorithm, with a certain percentage of your data as opposed to using all k-1 folds, ShuffleSplit is an attractive option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, random_state=None)\n",
    "# X is the feature set and y is the target\n",
    "for train_index, test_index in skf.split(X,y):\n",
    "    # Split train-test\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                      random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators = 100, random_state = 42)\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.4155485893416928\n"
     ]
    }
   ],
   "source": [
    "y_pred_kfold = rf.predict(X_test)\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred_kfold)) \n",
    "mean_squared_error=metrics.mean_squared_error(y_test, y_pred_kfold)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
